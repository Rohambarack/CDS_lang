{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup, importing modules\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 17:10:03.902597: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 17:10:03.907335: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 17:10:03.958617: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 17:10:04.991545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "#greyscale\n",
    "\n",
    "\n",
    "\n",
    "def grey_normalize_image(image,bins = 255):\n",
    "\n",
    "    \"\"\" function for greyscaling in an image file, taking it's color histogram and normailizing it. \"\"\"\n",
    "    #greyscale\n",
    "    greyed_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #normalize\n",
    "    hist = cv2.calcHist([greyed_image],[0],None,[bins],[0,256])\n",
    "    normalized_hist = cv2.normalize(hist, hist, 0, 1.0, cv2.NORM_MINMAX)\n",
    "    #squeeze a dimension out\n",
    "\n",
    "    normalized_hist = np.squeeze(normalized_hist)\n",
    "\n",
    "\n",
    "    return(normalized_hist)\n",
    "\n",
    "def show_col_channels(img, bins = 255):\n",
    "    color = ('b','g','r')\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([img],[i],None,[bins],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,bins])\n",
    "    plt.show()\n",
    "\n",
    "def ch3_normalize_image(image,bins = 255):\n",
    "\n",
    "    \"\"\" function for an image file, taking it's color histograms and normailizing them. \"\"\"\n",
    "    color_histogram_list = []\n",
    "    for channel in range(0,3):\n",
    "\n",
    "        #normalize\n",
    "        hist = cv2.calcHist([image],[channel],None,[bins],[0,256])\n",
    "        normalized_hist = cv2.normalize(hist, hist, 0, 1.0, cv2.NORM_MINMAX)\n",
    "        #squeeze a dimension out\n",
    "        normalized_hist = np.squeeze(normalized_hist)\n",
    "        color_histogram_list.append(normalized_hist)\n",
    "    \n",
    "    #make it one array\n",
    "    color_histogram = np.concatenate(np.array(color_histogram_list))\n",
    "\n",
    "\n",
    "    return(color_histogram)\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "# jimshow commisioned from utils\n",
    "def jimshow(image, title=False):\n",
    "    \"\"\"imshow with matplotlib dependencies \n",
    "    \"\"\"\n",
    "    # Acquire default dots per inch value of matplotlib\n",
    "    dpi = mpl.rcParams['figure.dpi']\n",
    "\n",
    "    height, width, depth = image.shape\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    if depth == 1:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "      \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def jimshow_channel(image, title=False):\n",
    "    \"\"\"\n",
    "    Modified jimshow() to plot individual channels\n",
    "    \"\"\"\n",
    "    # Acquire default dots per inch value of matplotlib\n",
    "    dpi = mpl.rcParams['figure.dpi']\n",
    "\n",
    "    height, width = image.shape\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    plt.imshow(image, cmap='gray')\n",
    "      \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grey_normalize_image(image):\n",
    "\n",
    "    \"\"\" function for greyscaling in an image file, and normailizing it. \"\"\"\n",
    "    #greyscale\n",
    "    greyed_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #normalize\n",
    "    normalized = greyed_image/255.0\n",
    "    #reshape\n",
    "    normalized = normalized.reshape(-1, 1024)\n",
    "    #squeeeze out a dimension\n",
    "    normalized = np.squeeze(normalized)\n",
    "\n",
    "\n",
    "    return(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_grey =[]\n",
    "for image in X_train:\n",
    "    temp_norm_im = grey_normalize_image(image)\n",
    "    X_train_normalized_grey.append(temp_norm_im)\n",
    "\n",
    "X_test_normalized_grey =[]\n",
    "for image in X_test:\n",
    "    temp_norm_im = grey_normalize_image(image)\n",
    "    X_test_normalized_grey.append(temp_norm_im)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(tol=0.2, \n",
    "                         solver='saga',\n",
    "                         multi_class='multinomial',\n",
    "                         random_state = 42).fit(X_train_normalized_grey, y_train)\n",
    "#predict\n",
    "prediction = classifier.predict(X_test_normalized_grey)\n",
    "#conf_matrix\n",
    "cm = np.array2string(metrics.confusion_matrix(y_test,prediction))\n",
    "#report\n",
    "cr = metrics.classification_report(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=42).fit(X_train_ch3, y_train)\n",
    "#predict\n",
    "prediction = classifier.predict(X_test_ch3)\n",
    "#conf_matrix\n",
    "cm = np.array2string(metrics.confusion_matrix(y_test,prediction))\n",
    "#report\n",
    "cr = metrics.classification_report(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../out/log_long_tol_report.txt', 'w')\n",
    "f.write('Logistic Classifier output\\n\\nClassification Report\\n\\n{}\\n\\nConfusion Matrix\\n\\n{}\\n'.format(cr, cm))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
